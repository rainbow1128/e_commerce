# nginx
## the user and group should exist before starting server
user  {{ os_username }}  {{ os_user_group }};
worker_processes  1;

# logging level can also be `debug`, `info`, `error`
error_log  logs/error.log    {{ logging_level }};

events {
    worker_connections  {{ max_num_conns }};
}

http {
    include       ../mime.types;
    default_type  application/octet-stream;
    # nginx-module-vts has to be statically built within nginx server
    vhost_traffic_status_zone  shared:vts_stats_shr:3m;
    vhost_traffic_status_histogram_buckets  0.04 0.1  0.3  0.5  1 5 10;
    vhost_traffic_status_filter  on;
    vhost_traffic_status_filter_max_node  145  $upstream_addr::non-stream-file::*   $upstream_addr::stream-elm-chunk::*;

    sendfile        on;
    keepalive_timeout  {{ http_keepalive_timeout_secs }};
    limit_conn_zone  $binary_remote_addr  zone=lmt_client_conns_state:1m;
    limit_req_zone   $binary_remote_addr  zone=lmt_client_reqs_state:3m  rate={{ reqs_per_sec }}r/s;
    limit_conn_status  503;
    limit_req_status   429;

    # the cache path has to be present before starting the server
    proxy_cache_path  {{ pxy_cch_basepath }}  levels=2:2  inactive={{ pxy_cch_inactive_mins }}m  use_temp_path=off   max_size={{ pxy_cch_max_space_mb }}m  keys_zone=pxy_cch_keyzone:1m;
    # nginx will pass the 2nd request and NOT cache the response of the 2nd request
    # , nginx still waits for caching response of the 1st request
    proxy_cache_lock_timeout  {{ pxy_cch_lock_timeout }}s;
    proxy_cache_lock_age      {{ pxy_cch_lock_timeout }}s; # nginx will pass the 2nd request and cache the response of the 2nd request
    proxy_read_timeout        43s; # between 2 successive reads  (on TCP/UDP packet)
    proxy_send_timeout        37s; # between 2 successive writes (on TCP/UDP packet)

    upstream media_backend_app {
        {% for item in backend_srv_iteration %}
            server {{ item.hostname }}:{{ item.port }}  max_conns={{ item.max_conns }}  max_fails={{ item.max_fails }} fail_timeout={{ item.retry_after_unavail_secs }}s  weight=3;
        {% endfor %}
        keepalive   15;
    }

    server {
        listen       {{ pxy_srv_port }}  ssl  http2;
        server_name  {{ pxy_srv_hostname }};
        error_page   404 410              /404.html;
        error_page   500 502 503 504  515 /50x.html;
        ssl_certificate      {{ pxy_srv_ssl_cert_path }};
        ssl_certificate_key  {{ pxy_srv_ssl_privkey_path }};
        ssl_protocols    TLSv1.3  TLSv1.2;
        ssl_session_cache  shared:my_tls_sess_base:3m; ## works only after v1.23.2
        ssl_session_tickets      on;
        ssl_session_timeout      {{ pxy_srv_ssl_sess_timeout_mins }}m;

        location / {
            vhost_traffic_status_filter_by_set_key   defaulterror   default_error::*;
            limit_rate   2k;
            return  400;
        }

        location /status {
            vhost_traffic_status_display;
            vhost_traffic_status_display_format  html;
            vhost_traffic_status_bypass_limit    off;
            vhost_traffic_status_bypass_stats    on;
            # TODO
            # (1) allow more IPs to access this endpoint
            # (2) authorization with JWT or OAuth
            allow  127.0.0.1;
            deny   all;
        }

        location  /file {
            include ./loc_proxy_common.conf;
            limit_conn  lmt_client_conns_state  {{ cps_nstream }};
            limit_req  zone=lmt_client_reqs_state  burst={{ qps_minus1 }};
            # for non-stream file, use stale cached response on updating, error, and timeout
            proxy_cache_use_stale   error timeout updating;
            vhost_traffic_status_filter_by_set_key  $uri  $upstream_addr::non-stream-file::*;
        } # end of location

        location  /file/stream/seek {
            include ./loc_proxy_common.conf;
            limit_conn  lmt_client_conns_state  {{ cps_stream }};
            limit_req  zone=lmt_client_reqs_state  burst={{ qps_minus1 }};
            # for streaming element, use stale cached response only on updating
            proxy_cache_use_stale   updating;
            vhost_traffic_status_filter_by_set_key  $uri  $upstream_addr::stream-elm-chunk::*;
        } # end of location block
    } # end of server block
} # end of http block
